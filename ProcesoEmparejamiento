Luego de explorar nuestra base de datos, estamos listos para realizar la implementación de la metodología. Empezaremos por la probabilidad de participación en el programa.

## **Propensity Score Matching** 
Si bien hay dos filosofías acerca del uso del emparejamiento, las dos comparten una base. Primero, hay un cálculo de la probabilidad de participar en el programa; segundo, hay una revisión del soporte común. Después, los pasos de verificación de la calidad del emparejamiento pueden variar. En esta sección exploraremos los pasos en común. Posteriormente veremos las particularidades.

###- Cálculo de la probabilidad de participación
Como hemos visto en clase, podemos estimar la probabilidad de participación en el programa mediante un modelo probit que use las variables que se relacionan con la participación en el programa y con la variable de interés. Para el efecto, se evalúan modelos que incluyan las variables observables.

```{r}
vars_x <- c('Dummy_100_DisEstTMF2',
 'Dummy_200_DisEstTMF2',
 'Dummy_300_DisEstTMF2',
 'Dummy_400_DisEstTMF2',
 'Dummy_500_DisEstTMF2',
 'Dummy_600_DisEstTMF2',
 'LnDistCBD72',
 'LnDistTroTMF2',
 'Residential',
 'Industrial',
 'Commercial',
 'Facilities',
 'Vacant',
 'Other',
 'MixUses',
 'StrataLevel_1_',
 'StrataLevel_2_',
 'StrataLevel_3_',
 'StrataLevel_4_',
 'StrataLevel_5_',
 'StrataLevel_6_',
 'LogBuiltupAreaBffa_',
 'LnIndiceManzanas',
 'LnIndiceParques',
 'LnIndiceVias',
 'LnDensidad_Eq',
 'LnDensidadPob',
 'LnProperties',
 'LnParcel_Area',
 'PropArea',
 'Areasqmts_',
 'Areasqmt_f_',
 'DistCBD72StrataLevel_3_',
 'DistCBD72StrataLevel_4_',
 'DistCBD72Dummy_500_DisEstTMF2',
 'DistCBD72Vacant',
 'DistCBD72Properties',
 'DistCBD72Parcel_Area')
d_logit <- glm(D ~ ., 
                # link puede ser probit o logit
                family = binomial(link = "logit"),        
                data = suelos_psm[c(vars_x, "D")]) 

tidy(d_logit)
```

Incluimos los valores predichos en la variable pscore.
```{r}
datos_pscore <- d_logit %>% 
  augment(type.predict = "response", newdata = suelos_psm) %>% 
  rename(pscore = .fitted) %>% 
  select(-starts_with(".")) 
```

Ahora, podemos observar cómo lucen las distribuciones de probabilidad de ser tratado, para los dos grupos.

```{r}
datos_pscore %>% 
  ggplot(aes(x = pscore, color = D)) +
  geom_density() +
  labs(x = "Probabilidad de ser tratado",
       y = "Densidad") +
  scale_color_discrete(name = element_blank(), 
                       labels = c("No Participante", "Participante")) +
  theme_bw() +
  theme(legend.position = "bottom")
  
```

Ya contamos con probabilidades predichas de la participación al programa. Estas serán nuestro insumo para la identificar a los “clones”.

### Definición del Soporte Común
La idea del soporte común es poder contar, para cada probabilidad, con casos de participantes y de no participantes. Esto nos permitirá descartar a quienes no podrán emparejarse. 

```{r}

datos_pscore %>% 
  group_by(D) %>% 
  summarise(min_pscore = min(pscore),
         max_pscore = max(pscore)
         ) %>% distinct(D, min_pscore, max_pscore)
min_T <- datos_pscore[which(datos_pscore$D), "pscore"] %>% min()
max_C <- datos_pscore[which(!datos_pscore$D),"pscore"] %>% max()

```

De esta forma, no serán tenidos en cuenta los participantes con probabilidades de participación que superen la máxima probabilidad del grupo de control (`max_C`), ni no participantes con probabilidades inferiores a la mínima probabilidad del grupo de tratamiento `min_T`.

```{r}

n_datos_pscore <- datos_pscore %>% 
  filter(D & pscore <= max_C | !D & pscore >= min_T)

```

Esto resulta en un pequeño cambio
```{r}
count(datos_pscore, D) %>% mutate(datos = "antes") %>% 
  bind_rows(count(n_datos_pscore, D) %>% mutate(datos = "después")) %>% 
  pivot_wider(names_from = "D", values_from = "n")
```

## Emparejamiento como parte del análisis
Esta sección se desarrolla en Stata, para lo cual se requiere la instalación de las siguientes librerías y la lectura de la base:

```{stata libs, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
ssc install psmatch2, replace
net from http://www.stata-journal.com/software/sj5-3
net install st0026_2

cd "C:\directorio\data\"
use "emparejamiento_base.dta", clear

```

###Calidad del emparejamiento
Con el comando pscore podemos dividir las observaciones en un número óptimo de bloques de manera que dentro de éstos la probabilidad media del grupo de control no sea estadísticamente diferente de la probabilidad media del grupo de tratamiento. Si se encuentra que dentro de un mismo bloque la probabilidad de participación es estadísticamente diferente, se divide el bloque en dos. Una vez se determina el número de bloques mediante este procedimiento el programa prueba, bloque por bloque, que no existan diferencias estadísticamente significativas entre los individuos de tratamiento y control para las variables incluidas para predecir la probabilidad de participación. Luego de esto, impone el soporte común.

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
pscore D $X, pscore(pscore_b) blockid(id) comsup det //Esta estimación replica el Resultado 6.3 del Libro

```


Para evaluar la calidad del emparejamiento también podemos estimar el modelo probit, con las características especificadas, controlando por la probabilidad predicha. Los coeficientes asociados a las características de los individuos no deben ser estadísticamente significativos:


```{stata leer, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
dprobit D pscore $X

```

### Selección de un algoritmo de emparejamiento
El comando psmatch2 puede calcular el propensity score y tener en cuenta únicamente a quienes se encuentran dentro del soporte común. Con este comando realizaremos las estimaciones del impacto del programa bajo diferentes algoritmos de emparejamiento, en lo cuales podemos obtener el impacto del programa en la fila ATT:

#### Estimador PSM por vecino más cercano
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
# 1 vecino
psmatch2 D $X, outcome(ha_nchs2) n(1) com

# 5 vecinos
psmatch2 D $X, outcome(ha_nchs2) n(1) com
```

#### Estimador PSM con distancia máxima
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
psmatch2 D $X, outcome(ha_nchs2) radius caliper(0.005)
```

####Emparejamiento por kernel, soporte común 
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}

psmatch2 D $X, outcome(ha_nchs2) com kernel  //Esta estimación replica parte del Resultado 6.6 del Libro
bootstrap r(att) : psmatch2 D $X, out(ha_nchs2) com kernel //Esta estimación replica parte del Resultado 6.6 del Libro 
```

 
#### Estimador por lineal local, soporte común
```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}

psmatch2 D $X, llr outcome(ha_nchs2) common
bootstrap r(att) : psmatch2 D $X, llr outcome(ha_nchs2) common
```

#### Dobles diferencias emparejadas
Por último, pero no por ello menos importante, una bondad de este método se constituye en su versatilidad para implementarse en conjunto con otras metodologías. Con la base de datos con la que contamos para el caso del programa canasta, por ejemplo, podemos implementar la metodología de diferencias en diferencias aprovechando la información adicional que nos ofrece el método de emparejamiento. Para esto, de la misma manera que cuando hicimos diferencias en diferencias, generamos una variable que nos muestre la diferencia de la variable resultado entre el periodo posterior y el periodo previo. Después, implementamos la misma sintaxis que hemos visto para el caso de un solo periodo, con las diferentes opciones, cambiando la variable resultado por la que acabamos de crear, como, en el siguiente ejemplo para el caso del vecino más cercano:

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}

gen delta_ha = ha_nchs2 - ha_nchs1
psmatch2 D $X, outcome(delta_ha)
```

## Emparejamiento como preprocesamiento

El objetivo de la función es crear dos conjuntos de datos balanceados, que puedan ser analizados más adelante mediante un modelo. Usaremos el paquete MatchIt, especialmente su función matchit. Su especificación típica sería 

```{r eval=FALSE, include=TRUE}
matchit(TRATAMIENTO ~ COVARIABLES, 
        data = datos, 
        method = "nearest", distance = "logit", discard = "none")
```

Se puede especificar diferentes métodos (e.g. exacto, óptimo, o completo) y diferentes distancias (e.g. mahalanobis). Como vemos, el resultado es un conjunto de datos y no una estimación. En este caso, los diferentes métodos son usados para definir los dos conjuntos, pero no para la estimación. 

Vemos que el emparejamiento descartó cinco observaciones, correspondientes al soporte común.

```{r}

emparejamiento <- matchit(D ~ personas + orden_n + ocupado_jefe + educa_jefe + ingresos_hogar_jefe,
                          data = canasta_psm, discard = "both")

emparejamiento

```

### Calidad del emparejamiento
Para evaluar su calidad, podemos ver un resumen de forma gráfica. En la imagen vemos los registros sin emparejar con base en el soporte común. También, vemos otros datos que no tuvieron pareja en el conjunto de no participantes.

```{r}
plot(emparejamiento,  type = "jitter", interactive = FALSE)
```

Podemos explorar la distribución antes y después del emparejamiento, donde vemos que son similares, aunque no eran tan diferentes antes del proceso. La gráfica nos muestra una pequeña disminución en la densidad cerca del puntaje de 0.4 en la probabilidad de participación.

```{r}

plot(emparejamiento,  type = "hist")
```

Otra opción es ver los cambios en la diferencia de medias estandarizada. El paquete Cobalt tiene esta opción por medio de una gráfica de Love. Se espera que el SMD sea menor 0.1.

```{r message=FALSE, warning=FALSE}
love.plot(emparejamiento, 
           drop.distance = TRUE, 
           var.order = "unadjusted",
           abs = FALSE,
           line = TRUE, 
           thresholds = c(m = .1),
           stars = "raw")
```
```{r}
bal.plot(emparejamiento, which = "both")
```

```{r}
CreateTableOne(data   = match.data(emparejamiento), 
               vars   = names(canasta_psm),
               strata = "D") %>% print(smd = TRUE)
```

Estas son las tablas de resumen del emparejamiento en matchit.
```{r}
emparejamiento %>% summary(standardize = TRUE)
```
